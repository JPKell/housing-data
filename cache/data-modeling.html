
        <div class="row mt-5" style="height:300px;">
            <img src="/static/banner-home.jpg" alt="Homes" style="width:100%;height:300px;object-fit: cover;">
        </div>    
        <h1 class="mt-5">Build the data model</h1>
        <p> 
            There are multiple models to be built and evaluated. A collection of regression algorithms will be used to build the model.
            Once the models are built, they will be evaluated using cross fold validation. Stacking will also be used to develop a 
            stacked model. The best model will be used to build to production model.
        </p>
        <hr class="my-5" />
        <h2>Models</h2>
        <p> 
            The data is a linear regression problem. I evaluated the following models:
        </p>
        <div class="row">
            <div class="col-6 p-1"><div class="card h-100 text-center bg-success text-white"><div class="card-body">LinearRegression()</div></div></div><div class="col-6 p-1"><div class="card h-100 text-center bg-success text-white"><div class="card-body">Ridge(alpha=15.4)</div></div></div><div class="col-6 p-1"><div class="card h-100 text-center bg-success text-white"><div class="card-body">Lasso(alpha=0.0006)</div></div></div><div class="col-6 p-1"><div class="card h-100 text-center bg-success text-white"><div class="card-body">DecisionTreeRegressor(max_depth=5)</div></div></div><div class="col-6 p-1"><div class="card h-100 text-center bg-success text-white"><div class="card-body">RandomForestRegressor(max_depth=5, n_estimators=30)</div></div></div><div class="col-6 p-1"><div class="card h-100 text-center bg-success text-white"><div class="card-body">GradientBoostingRegressor()</div></div></div>
        </div> 
        <hr class="my-5" />
        <h2>Scaling</h2>
        <p> 
            The data is skewed right. Scaling should help to normalize the data. During model building I evaluated 4
            different scaling methods. 
        </p>
        <p><strong>Scalers used:</strong> StandardScaler, MinMaxScaler, RobustScaler</p>
        <p>In the end none of the scalers improved the model.</p>
        <hr class="my-5" />
        <h2>Cross fold validation </h2>
        <p> 
            Root Mean Squared Error (RMSE) and Standard Deviation (SD) are both measures of the 
            spread of data. However, they are used in different contexts and have different 
            interpretations when evaluating a linear regression model. RMSE is a metric used to 
            evaluate the accuracy of a regression model and represents the average magnitude of 
            the errors in the predictions. SD is a measure of the variability of the data around
            the mean. In the context of evaluating a linear regression model, SD is often used 
            to assess the goodness of fit of the model.
        </p>
        <p>    
            The results of many runs are evaluated to determine the best model. The results of 
            a single pass with 5 folds are as follows:
        </p>
        <div class="row overflow-auto">
            <table class="table table-striped table-hover table-sm ">
                <thead>
                    <tr>
                        <th scope="col">Model</th>
                        <th scope="col" style="width:10%;">StandardScaler</th>
                        <th scope="col" style="width:10%;">Std dev.</th>
                        <th scope="col" style="width:10%;">MinMaxScaler</th>
                        <th scope="col" style="width:10%;">Std dev.</th>
                        <th scope="col" style="width:10%;">RobustScaler</th>
                        <th scope="col" style="width:10%;">Std dev.</th>
                        <th scope="col" style="width:10%;">None</th>
                        <th scope="col" style="width:10%;">Std dev.</th>
                    </tr>
                </thead>
                <tbody>
                    <tr><td>LinearRegression</td><td class="">34,480.04</td><td class="">6,341.46</td><td class="">34,103.44</td><td class="">9,557.52</td><td class="">35,205.49</td><td class="">4,530.55</td><td class="">35,985.54</td><td class="">7,864.66</td></tr><tr><td>Ridge</td><td class="">35,298.73</td><td class="">5,190.19</td><td class="">37,293.13</td><td class="bg-warning text-dark">3,398.10</td><td class="">34,693.77</td><td class="">5,748.44</td><td class="">34,629.29</td><td class="">6,350.07</td></tr><tr><td>Lasso</td><td class="">34,361.36</td><td class="">6,525.09</td><td class="">35,775.72</td><td class="">8,245.79</td><td class="">35,149.75</td><td class="">8,806.17</td><td class="">35,424.32</td><td class="">4,447.82</td></tr><tr><td>DecisionTreeRegressor</td><td class="">37,906.15</td><td class="bg-warning text-dark">4,561.84</td><td class="">38,294.33</td><td class="">7,012.15</td><td class="">38,691.57</td><td class="">4,074.87</td><td class="">39,673.67</td><td class="">9,612.20</td></tr><tr><td>RandomForestRegressor</td><td class="">32,788.69</td><td class="">7,089.44</td><td class="">32,382.88</td><td class="">4,894.75</td><td class="">32,635.09</td><td class="bg-warning text-dark">2,030.93</td><td class="">32,118.98</td><td class="">4,669.90</td></tr><tr><td>GradientBoostingRegressor</td><td class="bg-warning text-dark">27,708.73</td><td class="">5,379.70</td><td class="bg-warning text-dark">31,753.90</td><td class="">10,357.98</td><td class="bg-warning text-dark">32,628.28</td><td class="">10,292.30</td><td class="bg-warning text-dark">26,921.99</td><td class="bg-warning text-dark">2,108.60</td></tr>
                </tbody>
            </table>
        </div>
        <p> Over many of runs it was clear that the best model was the <strong>Gradient boosting</strong> model. </p>

        <hr class="my-5" />
        <h2>Stacking </h2>
        <p> 
            Stacking is a method of combining the results of multiple models. The stacking model is built using the results of the
            best models from the cross fold validation. The results of the stacking model are as follows:
        </p>
        <p><strong>Models used:</strong> LinearRegression, Ridge, Lasso, DecisionTreeRegressor, RandomForestRegressor, GradientBoostingRegressor</p>
        <p><strong>RMSE this run:</strong> &nbsp; 33,490.86</p>
        <p>
            Over 10 runs the average RMSE was 31,140.59.
            The Gradient boosting model was the best model so far.
        </p>
        <hr class="my-5" />
        <p class="text-center">Continue the process by further <a class="text-secondary" href="/model-evaluation">evaluating the model</a>.</p>
        <hr class="my-5" />
        <div class="row">
            <div class="accordion accordion-flush my-3 mb-5" id="code">
                <div class="accordion-item">
                    <h2 class="accordion-header" id="headingOne">
                        <button class="accordion-button bg-secondary text-white py-2" type="button" data-bs-toggle="collapse" data-bs-target="#collapseData">
                        Page code
                        </button>
                    </h2>
                    <div id="collapseData" class="accordion-collapse collapse" data-bs-parent="#code">
                        <div class="accordion-body">
                            <div class="row overflow-auto">
                                <pre>import os, pickle
# Third party imports
from flask import url_for
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler
from sklearn.linear_model  import Lasso, LinearRegression, Ridge
from sklearn.tree          import DecisionTreeRegressor
from sklearn.ensemble      import RandomForestRegressor, GradientBoostingRegressor
# Local imports
import model
import style

def html() -&gt; str:
    ''' Returns the HTML for the page. '''

    # Load a cached version of the page if it exists
    if os.path.exists('cache/data-modeling.html'):
        with open('cache/data-modeling.html', 'r') as f:
            return f.read()

    # Load the pickled data. There may be issues if the pages are run out of order and the model is not yet cached.
    # perhapts we keep the pkl files around when we flush the cache?
    train_df = pd.read_pickle('data/df_keep.pkl')
    target = pd.read_pickle('data/target.pkl')

    # Models
    linear = LinearRegression()
    ridge  = Ridge(alpha=15.4)
    lasso  = Lasso(alpha=0.0006)
    dec_tree    = DecisionTreeRegressor(criterion='squared_error', max_depth=5)
    rand_forest = RandomForestRegressor(n_estimators=30, criterion='squared_error', max_depth=5)
    grad_boost  = GradientBoostingRegressor(n_estimators=100)

    # The tuple is for the stacker which needs a list of tuples
    model_list = [linear, ridge, lasso, dec_tree, rand_forest, grad_boost]
    
    model_list_cards = ''
    for mod in model_list:
        model_list_cards += f'''&lt;div class="col-6 p-1"&gt;&lt;div class="card h-100 text-center bg-{style.bs_color} text-white"&gt;&lt;div class="card-body"&gt;{ mod }&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;'''
    # Scaling
    scaler_list = [StandardScaler, MinMaxScaler, RobustScaler, None]
    
    model_summary = {}
    folds = 5
    for mod in model_list:
        model_summary[mod.__class__.__name__] = {}
        for scaler in scaler_list:
            # Create a dictionary to store the results
            if scaler != None:
                model_summary[mod.__class__.__name__][scaler.__name__] = []
            else:
                model_summary[mod.__class__.__name__]['None'] = []

            result = model.evaluate_model(mod, scaler, train_df, target, folds=folds)

            # Store the results in the dictionary
            for d in result:
                if scaler != None:
                    model_summary[mod.__class__.__name__][scaler.__name__].append(d['RMSE'])
                else:
                    model_summary[mod.__class__.__name__]['None'].append(d['RMSE'])

    # Gather stats for the table so we can highlight the best results
    stats = {}
    for m in model_summary:
        for s in model_summary[m]:
            stats[s] = {'mean':[], 'sd':[]}
        break

    # Gather each scaler's mean and standard deviation for comparison
    for _model in model_summary:
        for _scaler, data in model_summary[_model].items():
            mean = np.mean(data)
            std  = np.std(data)
            stats[_scaler]['mean'].append(mean)
            stats[_scaler]['sd'].append(std)

    # Crossfold Validation table
    folds_table = ''
    for m in model_summary:
        folds_table += f'&lt;tr&gt;&lt;td&gt;{ m }&lt;/td&gt;'
        for scaler, data in model_summary[m].items():
            mean = np.mean(data)
            std  = np.std(data)

            is_min_mean = mean == min(stats[scaler]['mean'])
            is_min_std  = std == min(stats[scaler]['sd'])
        
            mean_hilight = style.table_highlight if is_min_mean else ''
            std_hilight  = style.table_highlight if is_min_std else ''

            folds_table += f'&lt;td class="{mean_hilight}"&gt;{mean:,.2f}&lt;/td&gt;&lt;td class="{std_hilight}"&gt;{std:,.2f}&lt;/td&gt;'        
        folds_table += '&lt;/tr&gt;'

    def evaluateModel(y_test, predictions, _model) -&gt; float:
        mse = model.mean_squared_error(y_test, predictions)
        rmse = round(np.sqrt(mse),3)
        return rmse

    def fitBaseModels(X_train, y_train, X_test, models):
        dfPredictions = pd.DataFrame()

        # Fit base model and store its predictions in dataframe.
        for i in range(0, len(models)):
            models[i].fit(X_train, y_train)
            predictions = models[i].predict(X_test)
            colName = str(i)
            # Add base model predictions to column of data frame.
            dfPredictions[colName] = predictions
        return dfPredictions, models

    def fitStackedModel(X, y):
        model = LinearRegression()
        model.fit(X, y)
        return model

    # Split data into train, test and validation sets.
    X_train, X_temp, y_train, y_temp = model.train_test_split(train_df, target, test_size=0.70)
    X_test, X_val, y_test, y_val = model.train_test_split(X_temp, y_temp, test_size=0.50)

    # Fit base and stacked models.
    dfPredictions, models = fitBaseModels(X_train, y_train, X_test, model_list)
    stackedModel          = fitStackedModel(dfPredictions, y_test)

    # Evaluate base models with validation data.
    dfValidationPredictions = pd.DataFrame()
    for i in range(0, len(models)):
        predictions = models[i].predict(X_val)
        colName = str(i)
        dfValidationPredictions[colName] = predictions

    # Evaluate stacked model with validation data.
    stackedPredictions = stackedModel.predict(dfValidationPredictions)

    stacked_rmse = evaluateModel(y_val, stackedPredictions, stackedModel)

    stacked_results = [37588.89,  32568.18, 35342.92, 26740.74, 33926.85, 26698.88, 31879.72, 31576.92, 28993.93, 26088.86]
    stacked_mean = np.mean(stacked_results)

    # Save the model list for model evaluation next page.
    with open('data/model_list.pkl', 'wb') as f:
        pickle.dump(model_list,f)

    # Read the code for the page
    with open('data_modeling.py', 'r') as f:
        code = f.read().replace('&lt;', '&lt;').replace('&gt;', '&gt;')

    html_str = f'''
        &lt;div class="row mt-5" style="height:300px;"&gt;
            &lt;img src="{url_for('static', filename='banner-home.jpg')}" alt="Homes" style="width:100%;height:300px;object-fit: cover;"&gt;
        &lt;/div&gt;    
        &lt;h1 class="mt-5"&gt;Build the data model&lt;/h1&gt;
        &lt;p&gt; 
            There are multiple models to be built and evaluated. A collection of regression algorithms will be used to build the model.
            Once the models are built, they will be evaluated using cross fold validation. Stacking will also be used to develop a 
            stacked model. The best model will be used to build to production model.
        &lt;/p&gt;
        &lt;hr class="my-5" /&gt;
        &lt;h2&gt;Models&lt;/h2&gt;
        &lt;p&gt; 
            The data is a linear regression problem. I evaluated the following models:
        &lt;/p&gt;
        &lt;div class="row"&gt;
            { model_list_cards }
        &lt;/div&gt; 
        &lt;hr class="my-5" /&gt;
        &lt;h2&gt;Scaling&lt;/h2&gt;
        &lt;p&gt; 
            The data is skewed right. Scaling should help to normalize the data. During model building I evaluated { len(scaler_list) }
            different scaling methods. 
        &lt;/p&gt;
        &lt;p&gt;&lt;strong&gt;Scalers used:&lt;/strong&gt; {', '.join([x.__name__ for x in scaler_list if not isinstance(x, type(None))])}&lt;/p&gt;
        &lt;p&gt;In the end none of the scalers improved the model.&lt;/p&gt;
        &lt;hr class="my-5" /&gt;
        &lt;h2&gt;Cross fold validation &lt;/h2&gt;
        &lt;p&gt; 
            Root Mean Squared Error (RMSE) and Standard Deviation (SD) are both measures of the 
            spread of data. However, they are used in different contexts and have different 
            interpretations when evaluating a linear regression model. RMSE is a metric used to 
            evaluate the accuracy of a regression model and represents the average magnitude of 
            the errors in the predictions. SD is a measure of the variability of the data around
            the mean. In the context of evaluating a linear regression model, SD is often used 
            to assess the goodness of fit of the model.
        &lt;/p&gt;
        &lt;p&gt;    
            The results of many runs are evaluated to determine the best model. The results of 
            a single pass with { folds } folds are as follows:
        &lt;/p&gt;
        &lt;div class="row overflow-auto"&gt;
            &lt;table class="{ style.table }"&gt;
                &lt;thead&gt;
                    &lt;tr&gt;
                        &lt;th scope="col"&gt;Model&lt;/th&gt;
                        &lt;th scope="col" style="width:10%;"&gt;StandardScaler&lt;/th&gt;
                        &lt;th scope="col" style="width:10%;"&gt;Std dev.&lt;/th&gt;
                        &lt;th scope="col" style="width:10%;"&gt;MinMaxScaler&lt;/th&gt;
                        &lt;th scope="col" style="width:10%;"&gt;Std dev.&lt;/th&gt;
                        &lt;th scope="col" style="width:10%;"&gt;RobustScaler&lt;/th&gt;
                        &lt;th scope="col" style="width:10%;"&gt;Std dev.&lt;/th&gt;
                        &lt;th scope="col" style="width:10%;"&gt;None&lt;/th&gt;
                        &lt;th scope="col" style="width:10%;"&gt;Std dev.&lt;/th&gt;
                    &lt;/tr&gt;
                &lt;/thead&gt;
                &lt;tbody&gt;
                    { folds_table }
                &lt;/tbody&gt;
            &lt;/table&gt;
        &lt;/div&gt;
        &lt;p&gt; Over many of runs it was clear that the best model was the &lt;strong&gt;Gradient boosting&lt;/strong&gt; model. &lt;/p&gt;

        &lt;hr class="my-5" /&gt;
        &lt;h2&gt;Stacking &lt;/h2&gt;
        &lt;p&gt; 
            Stacking is a method of combining the results of multiple models. The stacking model is built using the results of the
            best models from the cross fold validation. The results of the stacking model are as follows:
        &lt;/p&gt;
        &lt;p&gt;&lt;strong&gt;Models used:&lt;/strong&gt; {', '.join([x.__class__.__name__ for x in model_list])}&lt;/p&gt;
        &lt;p&gt;&lt;strong&gt;RMSE this run:&lt;/strong&gt; &nbsp; { stacked_rmse :,.2f}&lt;/p&gt;
        &lt;p&gt;
            Over { len(stacked_results) } runs the average RMSE was { stacked_mean :,.2f}.
            The Gradient boosting model was the best model so far.
        &lt;/p&gt;
        &lt;hr class="my-5" /&gt;
        &lt;p class="text-center"&gt;Continue the process by further &lt;a class="text-secondary" href="/model-evaluation"&gt;evaluating the model&lt;/a&gt;.&lt;/p&gt;
        &lt;hr class="my-5" /&gt;
        &lt;div class="row"&gt;
            &lt;div class="{ style.accordion } mb-5" id="code"&gt;
                &lt;div class="accordion-item"&gt;
                    &lt;h2 class="accordion-header" id="headingOne"&gt;
                        &lt;button class="{ style.code_button }" type="button" data-bs-toggle="collapse" data-bs-target="#collapseData"&gt;
                        Page code
                        &lt;/button&gt;
                    &lt;/h2&gt;
                    &lt;div id="collapseData" class="accordion-collapse collapse" data-bs-parent="#code"&gt;
                        &lt;div class="accordion-body"&gt;
                            &lt;div class="row overflow-auto"&gt;
                                &lt;pre&gt;{ code }&lt;/pre&gt;
                            &lt;/div&gt;
                        &lt;/div&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    '''

    # Cache the html
    with open('cache/data-modeling.html', 'w') as f:
        f.write(html_str)

    return html_str

 </pre>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    